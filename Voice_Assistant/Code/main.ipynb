{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import pyaudio\n",
    "import wave\n",
    "import os\n",
    "from pyChatGPT import ChatGPT\n",
    "from time import sleep\n",
    "from gtts import gTTS\n",
    "import mutagen\n",
    "import sounddevice as sd\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* recording\n",
      "* done recording\n"
     ]
    }
   ],
   "source": [
    "CHUNK = 1024\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 44100\n",
    "RECORD_SECONDS = 7\n",
    "WAVE_OUTPUT_FILENAME = \"audio.wav\"\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "stream = p.open(format=FORMAT,\n",
    "                channels=CHANNELS,\n",
    "                rate=RATE,\n",
    "                input=True,\n",
    "                frames_per_buffer=CHUNK)\n",
    "\n",
    "print(\"* recording\")\n",
    "\n",
    "frames = []\n",
    "\n",
    "for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "    data = stream.read(CHUNK)\n",
    "    frames.append(data)\n",
    "\n",
    "print(\"* done recording\")\n",
    "\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "p.terminate()\n",
    "\n",
    "wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "wf.setnchannels(CHANNELS)\n",
    "wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "wf.setframerate(RATE)\n",
    "wf.writeframes(b''.join(frames))\n",
    "wf.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andr√°s\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\whisper\\transcribe.py:78: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Write me a short poem about summer.\n"
     ]
    }
   ],
   "source": [
    "model = whisper.load_model(\"base\")\n",
    "result = model.transcribe(\"audio.wav\")\n",
    "result_text = result[\"text\"]\n",
    "language = result['language']\n",
    "print(result['text'])\n",
    "os.remove(\"audio.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ' Write me a short poem about summer.', 'segments': [{'id': 0, 'seek': 0, 'start': 0.0, 'end': 7.0, 'text': ' Write me a short poem about summer.', 'tokens': [50364, 23499, 385, 257, 2099, 13065, 466, 4266, 13, 50714], 'temperature': 0.0, 'avg_logprob': -0.46199503811922943, 'compression_ratio': 0.813953488372093, 'no_speech_prob': 0.11185072362422943}], 'language': 'en'}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summer sun, warm and bright,\n",
      "Bringing life to all in sight.\n",
      "Fields of green and flowers in bloom,\n",
      "Nature's beauty on full display, soon.\n",
      "Birds singing sweet melodies,\n",
      "Breezes blowing gently, a pleasant breeze.\n",
      "Children playing, laughter in the air,\n",
      "Summertime, a season without a care.\n",
      "So let us soak up the sun,\n",
      "And enjoy all that summer has begun.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "session_token = ''\n",
    "api = ChatGPT(session_token)\n",
    "resp = api.send_message(result_text)\n",
    "resp_txt = resp['message']\n",
    "print(resp['message'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "myobj = gTTS(text=resp_txt, lang=language, slow=False)\n",
    "myobj.save(\"response.wav\")\n",
    "\n",
    "filename = 'response.wav'\n",
    "# Extract data and sampling rate from file\n",
    "data, fs = sf.read(filename, dtype='float32')  \n",
    "sd.play(data, fs)\n",
    "status = sd.wait()  # Wait until file is done playing\n",
    "os.remove(\"response.wav\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eb26704fb02eae938e2f66a0b5827a81cc0efb2c666e8669733b73a6ffa9c7d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
